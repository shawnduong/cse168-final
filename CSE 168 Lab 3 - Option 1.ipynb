{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b79bdf",
   "metadata": {},
   "source": [
    "# CSE 168 Lab 3 - Option 1\n",
    "\n",
    "This notebook describes CSE 168 Lab 3 - Option 1 for students Shawn Duong, Chloe Engel, Charison Gill-Branion, and Isabella Montoya in the Fall semester of 2022.\n",
    "\n",
    "For this lab, we are training a model to detect 7 hand gestures. This follows the tutorial given in the lab handout by Nicholas Renotte.\n",
    "\n",
    "Before running this notebook, one should set up the venv and install the dependencies as per the tutorial:\n",
    "\n",
    "```\n",
    "python -m venv tfod\n",
    "\n",
    "source tfod/bin/activate # Linux\n",
    ".\\tfod\\Scripts\\activate # Windows \n",
    "\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=tfodj\n",
    "```\n",
    "\n",
    "Make sure that the notebook's kernel is tfodj as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3c2a2",
   "metadata": {},
   "source": [
    "# Part 1: Collecting Training Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3865881",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Dependencies\n",
    "\n",
    "We must install and import the dependencies. We need opencv-python in order to use computer vision related functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b61c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./tfod/lib/python3.10/site-packages (4.6.0.66)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in ./tfod/lib/python3.10/site-packages (from opencv-python) (1.22.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1ab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fa6ba",
   "metadata": {},
   "source": [
    "## Step 2: Define the Images to Collect\n",
    "\n",
    "We are collecting the hand gestures that make up \"Hello World,\" and saving 5 images per gesture. We can collect more training images by just re-running the code in step 4, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97268182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gestures we are training the model to detect.\n",
    "labels = [\"h\", \"e\", \"l\", \"o\", \"w\", \"r\", \"d\"]\n",
    "\n",
    "# The number of training images per gesture we will take.\n",
    "nImgs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9486176",
   "metadata": {},
   "source": [
    "## Step 3: Set Up File Structure\n",
    "\n",
    "We are going to save everything in `./tensorflow/workspaces/images/training_images/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e8298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to store our training images in.\n",
    "path = \"./tensorflow/workspace/images/training_images/\"\n",
    "\n",
    "# Create the path if it does not exist.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ca030",
   "metadata": {},
   "source": [
    "## Step 4: Capture Training Images From Webcam\n",
    "\n",
    "We capture 5 images per gesture from the webcam. We can press 'q' on our keyboard to quit early, or 'c' to capture an image when we're ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "507d0ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we have already collected images, we may want to skip this step.\n",
    "# If you have not collected images yet, set this to False.\n",
    "skipTraining = True\n",
    "\n",
    "if not skipTraining:\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Loop for all gestures we want to train.\n",
    "    for label in labels:\n",
    "\n",
    "        print(f\"Capturing images for: {label}\")\n",
    "\n",
    "        completed = 0\n",
    "        earlyExit = False\n",
    "\n",
    "        # Loop for however many images we wish to capture per gesture.\n",
    "        while completed < nImgs:\n",
    "\n",
    "            # Read from the camera and show it to us.\n",
    "            _, frame = cap.read()\n",
    "\n",
    "            try:\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # Webcam refresh rate.\n",
    "            time.sleep(0.01)\n",
    "\n",
    "            # Press 'q' to quit.\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                earlyExit = True\n",
    "                break\n",
    "\n",
    "            # Press 'c' to capture.\n",
    "            elif key == ord('c'):\n",
    "                # Capture and save the image.\n",
    "                completed += 1\n",
    "                print(f\"Capturing image {completed}/{nImgs}\")\n",
    "                cv2.imwrite(path+f\"{label}_{int(time.time())}.jpg\", frame)\n",
    "\n",
    "        if earlyExit:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f28a4d",
   "metadata": {},
   "source": [
    "## Step 5: Segment the Images Into Training and Testing\n",
    "\n",
    "Annotate the images with labelimg, and then move some into training and others into testing along with their annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5206d7",
   "metadata": {},
   "source": [
    "# Part 2: Training and Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57237f",
   "metadata": {},
   "source": [
    "## Step 1: Download and Compile TFOD\n",
    "\n",
    "We must download and install TFOD from TensorFlow's GitHub. We must compile all the proto files to do so. This is different for Linux and Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: you cannot perform this operation unless you are root.\n",
      "\u001b[?25l\u001b[?25hProcessing /home/skat/doc/repos/cse168-final/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: avro-python3 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.43.0)\n",
      "Requirement already satisfied: pillow in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (9.3.0)\n",
      "Requirement already satisfied: lxml in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (4.9.1)\n",
      "Requirement already satisfied: matplotlib in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (3.6.2)\n",
      "Requirement already satisfied: Cython in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (0.29.32)\n",
      "Requirement already satisfied: contextlib2 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.0.6)\n",
      "Requirement already satisfied: lvis in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (1.9.3)\n",
      "Requirement already satisfied: pandas in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.10.1)\n",
      "Requirement already satisfied: tensorflow_io in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (0.28.0)\n",
      "Requirement already satisfied: keras in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: sacrebleu<=2.2.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
      "Requirement already satisfied: regex in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n",
      "Requirement already satisfied: portalocker in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: colorama in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: tensorflow~=2.10.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.10.1)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.4)\n",
      "Requirement already satisfied: tensorflow-addons in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.19.0)\n",
      "Requirement already satisfied: immutabledict in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
      "Requirement already satisfied: seqeval in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: gin-config in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: oauth2client in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: opencv-python-headless in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.3)\n",
      "Requirement already satisfied: sentencepiece in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.97)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.69.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.10.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2022.6)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.4.0)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7.0)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.28.1)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.18)\n",
      "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.20.4)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.19.0)\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.20.0)\n",
      "Requirement already satisfied: orjson<4.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.8.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: objsize<0.6.0,>=0.5.2 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.5.2)\n",
      "Requirement already satisfied: cloudpickle~=2.2.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cycler>=0.10.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from lvis->object-detection==0.1) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (22.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.28.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow_io->object-detection==0.1) (0.28.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: docopt in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: certifi in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
      "Requirement already satisfied: tqdm in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
      "Requirement already satisfied: python-slugify in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (7.0.0)\n",
      "Requirement already satisfied: urllib3 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (22.12.6)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /home/skat/doc/repos/cse168-final/tfod/lib/python3.10/site-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (58.1.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5e2170>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5e24a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5cafb0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5cb550>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5cab60>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5cb0d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c356bf0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c356da0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c356f50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c357100>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c357790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tabulate/\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5ca440>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tabulate/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5cabf0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tabulate/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c5c8fa0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tabulate/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c357a90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tabulate/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c356bc0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/requests/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c357cd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/requests/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fa69c357eb0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/requests/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting requests<3.0.0,>=2.24.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "INFO: pip is looking at multiple versions of regex to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting regex\n",
      "  Using cached regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "INFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyyaml<6.0,>=5.1\n",
      "  Using cached PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl\n",
      "INFO: pip is looking at multiple versions of pytz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "INFO: pip is looking at multiple versions of pymongo to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached pymongo-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
      "INFO: pip is looking at multiple versions of pydot to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of pyarrow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyarrow<10.0.0,>=0.15.1\n",
      "  Using cached pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "INFO: pip is looking at multiple versions of py-cpuinfo to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting psutil>=5.4.3\n",
      "  Using cached psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of proto-plus to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Using cached proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
      "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.4-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of proto-plus to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading proto_plus-1.20.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.20.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.9-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.7-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading proto_plus-1.19.6-py3-none-any.whl (45 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.5-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.4-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.19.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.18.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.18.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.17.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.16.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.15.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto_plus-1.14.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading proto-plus-1.13.0.tar.gz (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.11.0.tar.gz (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.10.2.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.10.1.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.10.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.9.1.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.9.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.8.1.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.8.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading proto-plus-1.7.1.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-22.0-py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of orjson to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting orjson<4.0\n",
      "  Using cached orjson-3.8.3-cp310-cp310-manylinux_2_28_x86_64.whl (144 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "INFO: pip is looking at multiple versions of objsize to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting objsize<0.6.0,>=0.5.2\n",
      "  Using cached objsize-0.5.2-py3-none-any.whl (8.2 kB)\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kiwisolver>=1.1.0\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of kaggle to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of httplib2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting httplib2<0.21.0,>=0.8\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "INFO: pip is looking at multiple versions of hdfs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Using cached hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio!=1.48.0,<2,>=1.33.1\n",
      "  Using cached grpcio-1.51.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Using cached google_api_python_client-2.69.0-py2.py3-none-any.whl (10.7 MB)\n"
     ]
    }
   ],
   "source": [
    "# Make the repository where we will clone the TensorFlow models repo.\n",
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "    !git clone https://github.com/tensorflow/models ./models/\n",
    "    \n",
    "# For Linux.\n",
    "if os.name == \"posix\":\n",
    "    \n",
    "    # For Arch Linux.\n",
    "    if \"arch\" in os.uname().release:\n",
    "        !pacman -Syu protobuf\n",
    "        \n",
    "    # If you're not using Arch, you're probably on Ubuntu or some\n",
    "    # other Debian derivative and use apt.\n",
    "    else:\n",
    "        !apt-get install protobuf-compiler\n",
    "        \n",
    "    # Compile the proto files.\n",
    "    !cd ./models/research && protoc object_detection/protos/*.proto --python_out=. \\\n",
    "     && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
    "\n",
    "# For Windows.\n",
    "else:\n",
    "    # TODO.\n",
    "    protoc_path = \"tensorflow\\\\protoc\\\\\"\n",
    "    os.makedirs(protoc_path, exist_ok=True)\n",
    "    \n",
    "    !pip install wget\n",
    "    import wget\n",
    "    \n",
    "    # TODO: Clean\n",
    "    !cd {protoc_path} && dir && del /f \"protoc-3.15.6-win64.zip\"\n",
    "    \n",
    "    protoc_url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(protoc_url, out=protoc_path)\n",
    "    \n",
    "    !cd {protoc_path} && tar -xf protoc-3.15.6-win64.zip\n",
    "    \n",
    "    # PATH manual reset\n",
    "    #os.environ['PATH'] = \"\\\\Users\\\\chari\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\../../x64/vc14/bin;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\MATLAB\\\\R2021a\\\\bin;C:\\\\Program Files (x86)\\\\dotnet\\;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\ProgramData\\\\DockerDesktop\\\\version-bin;C:\\\\Users\\\\chari\\\\anaconda3;C:\\\\Users\\\\chari\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\chari\\\\anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\chari\\\\anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\chari\\\\anaconda3\\\\Scripts;C:\\\\python\\\\3.10.1\\\\Scripts\\\\;C:\\\\python\\\\3.10.1\\\\;C:\\\\Users\\\\chari\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\chari\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;\"\n",
    "    \n",
    "    # Add protoc to path\n",
    "    #os.environ['PATH'] += os.path.abspath(protoc_path + \"bin;\")\n",
    "    #print(os.environ['PATH'])\n",
    "    \n",
    "    !cd ./models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py\n",
    "    !cd ./models/research/slim && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab977451",
   "metadata": {},
   "source": [
    "## Step 2: Install TensorFlow and Upgrade Protobuf\n",
    "\n",
    "We will be using TensorFlow, so we should make sure it is installed before proceeding. We should also upgrade protobuf, since older versions may lead to an error about `builder.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You probably already have this installed, but just in case.\n",
    "!pip install tensorflow\n",
    "!pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fd919",
   "metadata": {},
   "source": [
    "## Step 3: Get The Pretrained Model\n",
    "\n",
    "A pretrained model is available at http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz. We just need to get it and extract it now before we can use it with our object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af797fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "# Make the directory.\n",
    "if not os.path.exists(\"./tensorflow/workspace/pretrained_models/\"):\n",
    "    os.makedirs(\"./tensorflow/workspace/pretrained_models/\")\n",
    "\n",
    "# For Linux.\n",
    "if os.name == \"posix\":\n",
    "    !wget {url}\n",
    "    !mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz ./tensorflow/workspace/pretrained_models/\n",
    "    !cd ./tensorflow/workspace/pretrained_models/ && tar xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "    \n",
    "# For Windows.\n",
    "else:\n",
    "    # TODO.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2583876",
   "metadata": {},
   "source": [
    "## Step 4: Create the Label Map\n",
    "\n",
    "We create a file `./tensorflow/workspace/annotations/label_map.pbtxt` containing our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94960110",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    {\"name\": \"h\", \"id\": 1},\n",
    "    {\"name\": \"e\", \"id\": 2},\n",
    "    {\"name\": \"l\", \"id\": 3},\n",
    "    {\"name\": \"o\", \"id\": 4},\n",
    "    {\"name\": \"w\", \"id\": 5},\n",
    "    {\"name\": \"r\", \"id\": 6},\n",
    "    {\"name\": \"d\", \"id\": 7},\n",
    "]\n",
    "\n",
    "data = \"\"\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    name = label[\"name\"]\n",
    "    idno = label[\"id\"]\n",
    "    \n",
    "    data += \"item {\\n\"\n",
    "    data += f\"\\tname: '{name}'\\n\"\n",
    "    data += f\"\\tid: {idno}\\n\"\n",
    "    data += \"}\\n\"\n",
    "\n",
    "if not os.path.exists(\"./tensorflow/workspace/annotations/\"):\n",
    "    os.makedirs(\"./tensorflow/workspace/annotations/\")\n",
    "    \n",
    "with open(\"./tensorflow/workspace/annotations/label_map.pbtxt\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6260b4",
   "metadata": {},
   "source": [
    "## Step 5: Copy the Model Config to the Training Folder\n",
    "\n",
    "We need to create a training folder and copy the model config over to it before we begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./tensorflow/workspace/models/model/\"):\n",
    "    os.makedirs(\"./tensorflow/workspace/models/model/\")\n",
    "\n",
    "# Linux.\n",
    "if os.name == \"posix\":\n",
    "    !cp ./tensorflow/workspace/pretrained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
    "     ./tensorflow/workspace/models/model/\n",
    "    \n",
    "# Windows.\n",
    "else:\n",
    "    # TODO.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b1fa0",
   "metadata": {},
   "source": [
    "## Step 6: Create TF Records\n",
    "\n",
    "We clone and run the author's scripts to generate the TF records used in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d44a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"GenerateTFRecord\"):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord\n",
    "\n",
    "!python GenerateTFRecord/generate_tfrecord.py -x \"./tensorflow/workspace/images/train\" \\\n",
    " -l \"./tensorflow/workspace/annotations/label_map.pbtxt\" -o \"./tensorflow/workspace/annotations/train.record\"\n",
    "!python GenerateTFRecord/generate_tfrecord.py -x \"./tensorflow/workspace/images/test\" \\\n",
    " -l \"./tensorflow/workspace/annotations/label_map.pbtxt\" -o \"./tensorflow/workspace/annotations/test.record\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fddbdb",
   "metadata": {},
   "source": [
    "## Step 7: Import Everything and Update the Config for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee095ba",
   "metadata": {},
   "source": [
    "We should import everything needed for training and detection now. We can update the config for transfer learning with our training images. If you get warnings about CPU optimization, ignore them -- it has to do with your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e38fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(\"./tensorflow/workspace/models/model/pipeline.config\")\n",
    "pconfig = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "with tf.io.gfile.GFile(\"./tensorflow/workspace/models/model/pipeline.config\", \"r\") as f:\n",
    "    pstr = f.read()\n",
    "    text_format.Merge(pstr, pconfig)\n",
    "    \n",
    "pconfig.model.ssd.num_classes = len(labels)\n",
    "pconfig.train_config.batch_size = 4\n",
    "pconfig.train_config.fine_tune_checkpoint = \"./tensorflow/workspace/pretrained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
    "pconfig.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pconfig.train_input_reader.label_map_path= \"./tensorflow/workspace/annotations/label_map.pbtxt\"\n",
    "pconfig.train_input_reader.tf_record_input_reader.input_path[:] = [\"./tensorflow/workspace/annotations/train.record\"]\n",
    "pconfig.eval_input_reader[0].label_map_path = \"./tensorflow/workspace/annotations/label_map.pbtxt\"\n",
    "pconfig.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\"./tensorflow/workspace/annotations/test.record\"]\n",
    "\n",
    "config = text_format.MessageToString(pconfig)\n",
    "\n",
    "with tf.io.gfile.GFile(\"./tensorflow/workspace/models/model/pipeline.config\", \"wb\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b941a",
   "metadata": {},
   "source": [
    "## Step 8: Train!\n",
    "\n",
    "It's finally time to run the training program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have already trained, we may want to skip this step.\n",
    "# If you have not collected trained yet, set this to False.\n",
    "skipTraining = True\n",
    "\n",
    "if not skipTraining:\n",
    "    !echo \"It's training time!\"\n",
    "    !python ./models/research/object_detection/model_main_tf2.py                 \\\n",
    "     --model_dir=./tensorflow/workspace/models/model/                            \\\n",
    "     --pipeline_config_path=./tensorflow/workspace/models/model/pipeline.config  \\\n",
    "     --num_train_steps=2000\n",
    "    !echo \"Done training.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
