{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b79bdf",
   "metadata": {},
   "source": [
    "# CSE 168 Lab 3 - Option 1\n",
    "\n",
    "This notebook describes CSE 168 Lab 3 - Option 1 for students Shawn Duong, Chloe Engel, Charison Gill-Branion, and Isabella Montoya in the Fall semester of 2022.\n",
    "\n",
    "For this lab, we are training a model to detect 4 hand gestures. This follows the tutorial given in the lab handout by Nicholas Renotte.\n",
    "\n",
    "Before running this notebook, one should set up the venv and install the dependencies as per the tutorial:\n",
    "\n",
    "```\n",
    "python -m venv tfod\n",
    "\n",
    "source tfod/bin/activate # Linux\n",
    ".\\tfod\\Scripts\\activate # Windows \n",
    "\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=tfodj\n",
    "```\n",
    "\n",
    "Make sure that the notebook's kernel is tfodj as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3865881",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Dependencies\n",
    "\n",
    "We must install and import the dependencies. We need opencv-python in order to use computer vision related functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b61c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./tfod/lib/python3.10/site-packages (4.6.0.66)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./tfod/lib/python3.10/site-packages (from opencv-python) (1.22.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1ab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fa6ba",
   "metadata": {},
   "source": [
    "## Step 2: Define the Images to Collect\n",
    "\n",
    "We are collecting the hand gestures that make up \"Hello World,\" and saving 5 images per gesture. We can collect more training images by just re-running the code in step 4, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97268182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gestures we are training the model to detect.\n",
    "labels = [\"h\", \"e\", \"l\", \"o\", \"w\", \"r\", \"d\"]\n",
    "\n",
    "# The number of training images per gesture we will take.\n",
    "nImgs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9486176",
   "metadata": {},
   "source": [
    "## Step 3: Set Up File Structure\n",
    "\n",
    "We are going to save everything in `./tensorflow/workspaces/images/training_images/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e8298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to store our training images in.\n",
    "path = \"./tensorflow/workspace/images/training_images/\"\n",
    "\n",
    "# Create the path if it does not exist.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ca030",
   "metadata": {},
   "source": [
    "## Step 4: Capture Training Images From Webcam\n",
    "\n",
    "We capture 5 images per gesture from the webcam. We can press 'q' on our keyboard to quit early, or 'c' to capture an image when we're ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "507d0ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing images for: h\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Loop for however many images we wish to capture per gesture.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m completed \u001b[38;5;241m<\u001b[39m nImgs:\n\u001b[1;32m     13\u001b[0m     \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Read from the camera and show it to us.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     _, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop for all gestures we want to train.\n",
    "for label in labels:\n",
    "    \n",
    "    print(f\"Capturing images for: {label}\")\n",
    "    \n",
    "    completed = 0\n",
    "    earlyExit = False\n",
    "    \n",
    "    # Loop for however many images we wish to capture per gesture.\n",
    "    while completed < nImgs:\n",
    "        \n",
    "        # Read from the camera and show it to us.\n",
    "        _, frame = cap.read()\n",
    "        \n",
    "        try:\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Webcam refresh rate.\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        # Press 'q' to quit.\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            earlyExit = True\n",
    "            break\n",
    "            \n",
    "        # Press 'c' to capture.\n",
    "        elif key == ord('c'):\n",
    "            # Capture and save the image.\n",
    "            completed += 1\n",
    "            print(f\"Capturing image {completed}/{nImgs}\")\n",
    "            cv2.imwrite(path+f\"{label}_{int(time.time())}.jpg\", frame)\n",
    "            \n",
    "    if earlyExit:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57237f",
   "metadata": {},
   "source": [
    "## Step 5: Download and Compile TFOD\n",
    "\n",
    "We must download and install TFOD from TensorFlow's GitHub. We must compile all the proto files to do so. This is different for Linux and Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the repository where we will clone the TensorFlow models repo.\n",
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "    !git clone https://github.com/tensorflow/models ./models/\n",
    "    \n",
    "# For Linux.\n",
    "if os.name == \"posix\":\n",
    "    \n",
    "    # For Arch Linux.\n",
    "    if \"arch\" in os.uname().release:\n",
    "        !pacman -Syu protobuf\n",
    "        \n",
    "    # If you're not using Arch, you're probably on Ubuntu or some\n",
    "    # other Debian derivative and use apt.\n",
    "    else:\n",
    "        !apt-get install protobuf-compiler\n",
    "        \n",
    "    # Compile the proto files.\n",
    "    !cd ./models/research && protoc object_detection/protos/*.proto --python_out=. \\\n",
    "     && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
    "\n",
    "# For Windows.\n",
    "else:\n",
    "    \n",
    "    # TODO.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab977451",
   "metadata": {},
   "source": [
    "## Step 6: Import and Install TensorFlow and Object Detection\n",
    "\n",
    "We will be using TensorFlow and object detection in our program and must install and import it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You probably already have this installed, but just in case.\n",
    "!pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da676f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodj",
   "language": "python",
   "name": "tfodj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
